{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/launchpad/miniforge3/envs/argus/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/launchpad/miniforge3/envs/argus/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./utils/data/Scraped News/temp_marketinsights_data_2024-08-13.csv']\n",
      "./utils/data/Scraped News/temp_marketinsights_data_2024-08-13.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>Article content</th>\n",
       "      <th>raw</th>\n",
       "      <th>raw2</th>\n",
       "      <th>People</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Certain A Shares of CanSino Biologics Inc. are...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/CAN...</td>\n",
       "      <td>6185</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>Certain A Shares of CanSino Biologics Inc. are...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Xue Feng Yu', 'Age': '60 year', 'Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German defence firm Renk appoints Manz-Siebje ...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/REN...</td>\n",
       "      <td>R3NK</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Aug 12 (Reuters) - German defence firm Renk Gr...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Susanne Wiegand', 'Age': '-', 'Posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRobot Corporation Appoints Michael J. Loparco...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/IRO...</td>\n",
       "      <td>IRBT</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>iRobot Corp. announced the addition of Michael...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Gary Cohen', 'Age': '63 year', 'Pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charter Communications, Inc. Appoints Simon Ca...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/CHA...</td>\n",
       "      <td>CHTR</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>Charter Communications, Inc. announced that Si...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Christopher Winfrey', 'Age': '48 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaaS Technology Inc. Announces Chief Financial...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/NAA...</td>\n",
       "      <td>REDU</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>NaaS Technology Inc. announced that Mr. Alex W...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Yang Wang', 'Age': '36 year', 'Posi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Certain A Shares of CanSino Biologics Inc. are...   \n",
       "1  German defence firm Renk appoints Manz-Siebje ...   \n",
       "2  IRobot Corporation Appoints Michael J. Loparco...   \n",
       "3  Charter Communications, Inc. Appoints Simon Ca...   \n",
       "4  NaaS Technology Inc. Announces Chief Financial...   \n",
       "\n",
       "                                                link ticker        date  \\\n",
       "0  https://www.marketscreener.com/quote/stock/CAN...   6185  2024-08-12   \n",
       "1  https://www.marketscreener.com/quote/stock/REN...   R3NK     Aug. 12   \n",
       "2  https://www.marketscreener.com/quote/stock/IRO...   IRBT     Aug. 12   \n",
       "3  https://www.marketscreener.com/quote/stock/CHA...   CHTR     Aug. 12   \n",
       "4  https://www.marketscreener.com/quote/stock/NAA...   REDU     Aug. 12   \n",
       "\n",
       "           source                                    Article content  \\\n",
       "0  S&P Capital IQ  Certain A Shares of CanSino Biologics Inc. are...   \n",
       "1         Reuters  Aug 12 (Reuters) - German defence firm Renk Gr...   \n",
       "2  S&P Capital IQ  iRobot Corp. announced the addition of Michael...   \n",
       "3  S&P Capital IQ  Charter Communications, Inc. announced that Si...   \n",
       "4  S&P Capital IQ  NaaS Technology Inc. announced that Mr. Alex W...   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "\n",
       "                                                raw2  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "\n",
       "                                              People  \n",
       "0  [{'Name': 'Xue Feng Yu', 'Age': '60 year', 'Po...  \n",
       "1  [{'Name': 'Susanne Wiegand', 'Age': '-', 'Posi...  \n",
       "2  [{'Name': 'Gary Cohen', 'Age': '63 year', 'Pos...  \n",
       "3  [{'Name': 'Christopher Winfrey', 'Age': '48 ye...  \n",
       "4  [{'Name': 'Yang Wang', 'Age': '36 year', 'Posi...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Pipeline issue to be resolved...\n",
    "Exact same code here but it works\n",
    "Run every week if needed\n",
    "\n",
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from utils.marketinsights import get_city_mapping, get_contact_information, get_industry, get_intersection, get_phone_mapping, label_country_by_city, label_country_by_phone, final_country, convert_to_datetime, AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = 'nomic-ai/nomic-embed-text-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "selection = 'marketinsights'\n",
    "directory = \"./utils/data/Scraped News/\"\n",
    "file_pattern = f\"temp_{selection}_data_*.csv\"\n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "print(files)\n",
    "latest_file = max(files, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "\n",
    "try:\n",
    "    existing = pd.read_csv('utils/data/Scrape/phoneextensions.csv')\n",
    "except FileNotFoundError:\n",
    "    existing = pd.DataFrame()\n",
    "\n",
    "phone_storage = get_phone_mapping(existing)\n",
    "city_storage = get_city_mapping()\n",
    "\n",
    "df = pd.read_csv(latest_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/launchpad/workspace/services/Argus/utils/marketinsights.py:187: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 187 of the file /Users/launchpad/workspace/services/Argus/utils/marketinsights.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(soup)\n",
      "/Users/launchpad/workspace/services/Argus/utils/marketinsights.py:208: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 208 of the file /Users/launchpad/workspace/services/Argus/utils/marketinsights.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(soup)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>Article content</th>\n",
       "      <th>raw</th>\n",
       "      <th>raw2</th>\n",
       "      <th>People</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Contact Information</th>\n",
       "      <th>Country_phone</th>\n",
       "      <th>Country_city</th>\n",
       "      <th>Country_candidates</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Certain A Shares of CanSino Biologics Inc. are...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/CAN...</td>\n",
       "      <td>6185</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>Certain A Shares of CanSino Biologics Inc. are...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Xue Feng Yu', 'Age': '60 year', 'Po...</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>{'Company Name': 'CanSino Biologics Inc.', 'Ad...</td>\n",
       "      <td>{China}</td>\n",
       "      <td>{China}</td>\n",
       "      <td>{China}</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>German defence firm Renk appoints Manz-Siebje ...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/REN...</td>\n",
       "      <td>R3NK</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Aug 12 (Reuters) - German defence firm Renk Gr...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Susanne Wiegand', 'Age': '-', 'Posi...</td>\n",
       "      <td>Consumer Cyclicals</td>\n",
       "      <td>{'Company Name': 'RENK Group AG', 'Address Lin...</td>\n",
       "      <td>{Germany}</td>\n",
       "      <td>{Germany}</td>\n",
       "      <td>{Germany}</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IRobot Corporation Appoints Michael J. Loparco...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/IRO...</td>\n",
       "      <td>IRBT</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>iRobot Corp. announced the addition of Michael...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Gary Cohen', 'Age': '63 year', 'Pos...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>{'Company Name': 'iRobot Corporation', 'Addres...</td>\n",
       "      <td>{United States, Canada}</td>\n",
       "      <td>{United States, United Kingdom}</td>\n",
       "      <td>{United States}</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charter Communications, Inc. Appoints Simon Ca...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/CHA...</td>\n",
       "      <td>CHTR</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>Charter Communications, Inc. announced that Si...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Christopher Winfrey', 'Age': '48 ye...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>{'Company Name': 'Charter Communications, Inc....</td>\n",
       "      <td>{United States, Canada}</td>\n",
       "      <td>{United States, United Kingdom}</td>\n",
       "      <td>{United States}</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaaS Technology Inc. Announces Chief Financial...</td>\n",
       "      <td>https://www.marketscreener.com/quote/stock/NAA...</td>\n",
       "      <td>REDU</td>\n",
       "      <td>Aug. 12</td>\n",
       "      <td>S&amp;P Capital IQ</td>\n",
       "      <td>NaaS Technology Inc. announced that Mr. Alex W...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en-US\" prefix=\"og...</td>\n",
       "      <td>[{'Name': 'Yang Wang', 'Age': '36 year', 'Posi...</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Unknown}</td>\n",
       "      <td>{Unknown}</td>\n",
       "      <td>{Unknown}</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Certain A Shares of CanSino Biologics Inc. are...   \n",
       "1  German defence firm Renk appoints Manz-Siebje ...   \n",
       "2  IRobot Corporation Appoints Michael J. Loparco...   \n",
       "3  Charter Communications, Inc. Appoints Simon Ca...   \n",
       "4  NaaS Technology Inc. Announces Chief Financial...   \n",
       "\n",
       "                                                link ticker        date  \\\n",
       "0  https://www.marketscreener.com/quote/stock/CAN...   6185  2024-08-12   \n",
       "1  https://www.marketscreener.com/quote/stock/REN...   R3NK     Aug. 12   \n",
       "2  https://www.marketscreener.com/quote/stock/IRO...   IRBT     Aug. 12   \n",
       "3  https://www.marketscreener.com/quote/stock/CHA...   CHTR     Aug. 12   \n",
       "4  https://www.marketscreener.com/quote/stock/NAA...   REDU     Aug. 12   \n",
       "\n",
       "           source                                    Article content  \\\n",
       "0  S&P Capital IQ  Certain A Shares of CanSino Biologics Inc. are...   \n",
       "1         Reuters  Aug 12 (Reuters) - German defence firm Renk Gr...   \n",
       "2  S&P Capital IQ  iRobot Corp. announced the addition of Michael...   \n",
       "3  S&P Capital IQ  Charter Communications, Inc. announced that Si...   \n",
       "4  S&P Capital IQ  NaaS Technology Inc. announced that Mr. Alex W...   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "\n",
       "                                                raw2  \\\n",
       "0  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "1  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "2  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "3  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "4  <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...   \n",
       "\n",
       "                                              People            Industry  \\\n",
       "0  [{'Name': 'Xue Feng Yu', 'Age': '60 year', 'Po...          Healthcare   \n",
       "1  [{'Name': 'Susanne Wiegand', 'Age': '-', 'Posi...  Consumer Cyclicals   \n",
       "2  [{'Name': 'Gary Cohen', 'Age': '63 year', 'Pos...          Technology   \n",
       "3  [{'Name': 'Christopher Winfrey', 'Age': '48 ye...          Technology   \n",
       "4  [{'Name': 'Yang Wang', 'Age': '36 year', 'Posi...           Utilities   \n",
       "\n",
       "                                 Contact Information            Country_phone  \\\n",
       "0  {'Company Name': 'CanSino Biologics Inc.', 'Ad...                  {China}   \n",
       "1  {'Company Name': 'RENK Group AG', 'Address Lin...                {Germany}   \n",
       "2  {'Company Name': 'iRobot Corporation', 'Addres...  {United States, Canada}   \n",
       "3  {'Company Name': 'Charter Communications, Inc....  {United States, Canada}   \n",
       "4                                                 {}                {Unknown}   \n",
       "\n",
       "                      Country_city Country_candidates        Country  \n",
       "0                          {China}            {China}          China  \n",
       "1                        {Germany}          {Germany}        Germany  \n",
       "2  {United States, United Kingdom}    {United States}  United States  \n",
       "3  {United States, United Kingdom}    {United States}  United States  \n",
       "4                        {Unknown}          {Unknown}        Unknown  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Industry'] = df['raw'].apply(get_industry)\n",
    "df['Contact Information'] = df['raw'].apply(get_contact_information)\n",
    "df['Country_phone'] = df['Contact Information'].apply(lambda x: label_country_by_phone(x, phone_storage))\n",
    "df['Country_city'] = df['Contact Information'].apply(lambda x: label_country_by_city(x, city_storage))\n",
    "df['Country_candidates'] = df.apply(lambda x: get_intersection(x.Country_phone, x.Country_city), axis=1)\n",
    "df['Country'] = df.apply(lambda x: final_country(x['Contact Information'], x.Country_candidates, tokenizer, model), axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the conversion functions\n",
    "df['Time'] = df['date'].apply(convert_to_datetime)\n",
    "df.drop(['date', 'raw', 'raw2'], axis=1, inplace=True)\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "selection = 'marketinsights'\n",
    "directory = \"./utils/data/Scraped News/\"\n",
    "output_file_path = f\"{directory}/{selection}_data_{current_date}.csv\"\n",
    "df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trying out sentiment scoring for article content\n",
    "'''\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "test_content = df.iloc[5]['Article content']\n",
    "print(test_content)\n",
    "\n",
    "# initialize our model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "\n",
    "def get_sentiment(text):\n",
    "    tokens = tokenizer.encode_plus(text, add_special_tokens=False)\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    # define our starting position (0) and window size (number of tokens in each chunk)\n",
    "    start = 0\n",
    "    window_size = 512\n",
    "    \n",
    "    # initialize probabilities list\n",
    "    probs_list = []\n",
    "    \n",
    "    start = 0\n",
    "    window_size = 510  # we take 2 off here so that we can fit in our [CLS] and [SEP] tokens\n",
    "    \n",
    "    loop = True\n",
    "    \n",
    "    while loop:\n",
    "        end = start + window_size\n",
    "        if end >= total_len:\n",
    "            loop = False\n",
    "            end = total_len\n",
    "        # (1) extract window from input_ids and attention_mask\n",
    "        input_ids_chunk = input_ids[start:end]\n",
    "        attention_mask_chunk = attention_mask[start:end]\n",
    "        # (2) add [CLS] and [SEP]\n",
    "        input_ids_chunk = [101] + input_ids_chunk + [102]\n",
    "        attention_mask_chunk = [1] + attention_mask_chunk + [1]\n",
    "        # (3) add padding upto window_size + 2 (512) tokens\n",
    "        input_ids_chunk += [0] * (window_size - len(input_ids_chunk) + 2)\n",
    "        attention_mask_chunk += [0] * (window_size - len(attention_mask_chunk) + 2)\n",
    "        # (4) format into PyTorch tensors dictionary\n",
    "        input_dict = {\n",
    "            'input_ids': torch.Tensor([input_ids_chunk]).long(),\n",
    "            'attention_mask': torch.Tensor([attention_mask_chunk]).int()\n",
    "        }\n",
    "        # (5) make logits prediction\n",
    "        outputs = model(**input_dict)\n",
    "        # (6) calculate softmax and append to list\n",
    "        probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "        probs_list.append(probs)\n",
    "    \n",
    "        start = end\n",
    "\n",
    "    stacks = torch.stack(probs_list)\n",
    "    shape = stacks.shape\n",
    "    with torch.no_grad():\n",
    "        # we must include our stacks operation in here too\n",
    "        stacks = torch.stack(probs_list)\n",
    "        # now resize\n",
    "        stacks = stacks.resize_(stacks.shape[0], stacks.shape[2])\n",
    "        # finally, we can calculate the mean value for each sentiment class\n",
    "        mean = stacks.mean(dim=0)\n",
    "    print(mean)\n",
    "    winner = torch.argmax(mean).item()\n",
    "    result = ['Positive', 'Negative', 'Neutral'][winner]\n",
    "    return result\n",
    "\n",
    "df['Sentiment'] = df['Article content'].apply(get_sentiment)\n",
    "for i, row in df.iterrows():\n",
    "    print('Content: \\n')\n",
    "    print(row['Article content'])\n",
    "    print('\\nSentiment: \\n')\n",
    "    print(row['Sentiment'])\n",
    "    print('**********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trying out labelling missing executives from company website\n",
    "'''\n",
    "\n",
    "from serpapi import GoogleSearch\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from serpapi import GoogleSearch\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def search_company_management(company_name, api_key):\n",
    "    # Define common terms used for management page\n",
    "    management_terms = {\n",
    "        \"Our Team\", \"Leadership\", \"Directors\", \n",
    "        \"Management\", \"Board\", \"Organization\"\n",
    "    }\n",
    "    \n",
    "    # Construct query with various combinations\n",
    "    queries = f\"({company_name} company website) AND ({' OR '.join(management_terms)})\"\n",
    "    \n",
    "    params = {\n",
    "        \"q\": queries,\n",
    "        \"engine\": \"google\",\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"num\": 10,\n",
    "        \"nfpr\": 1,\n",
    "        \"api_key\": api_key,\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    # Scraping each result page\n",
    "    storage = []\n",
    "    header = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) '\n",
    "                      'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "        }\n",
    "    for temp in results['organic_results']:\n",
    "        link = temp['link']\n",
    "        try:\n",
    "            response = requests.get(link, headers = header, timeout=10)\n",
    "            response.raise_for_status()  # Raise an exception if the request was unsuccessful\n",
    "\n",
    "            # Parse the HTML content of the page with BeautifulSoup\n",
    "            html_content = urllib.parse.unquote(response.text)\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            # Extract and clean text content\n",
    "            text_content = soup.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            if text_content.strip():\n",
    "                storage.append(text_content)\n",
    "        except:\n",
    "            print(f\"Unable to scrape {link}\")\n",
    "    return storage, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to scrape https://www.comparably.com/companies/stubhub/executive-team\n",
      "Unable to scrape https://pitchbook.com/profiles/company/13230-37\n",
      "Unable to scrape https://www.dnb.com/business-directory/company-profiles.stubhub_inc.30a2fb4082f9f3d30b41552d98df63ec.html\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "api_key = st.secrets['serp_api_key']\n",
    "company_name = 'StubHub'\n",
    "search_results, x = search_company_management(company_name, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/launchpad/miniforge3/envs/argus/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'PER', 'score': 0.9991996, 'word': 'Art Yegorov', 'start': 9, 'end': 20}\n",
      "{'entity_group': 'PER', 'score': 0.9996076, 'word': 'C', 'start': 0, 'end': 1}\n",
      "{'entity_group': 'PER', 'score': 0.9953915, 'word': '##risto', 'start': 1, 'end': 6}\n",
      "{'entity_group': 'PER', 'score': 0.7530372, 'word': '##pher Miller', 'start': 6, 'end': 17}\n",
      "{'entity_group': 'PER', 'score': 0.9991628, 'word': 'Na', 'start': 4, 'end': 6}\n",
      "{'entity_group': 'PER', 'score': 0.9269295, 'word': '##ku', 'start': 6, 'end': 8}\n",
      "{'entity_group': 'PER', 'score': 0.9974962, 'word': '##l Paul', 'start': 8, 'end': 14}\n",
      "{'entity_group': 'PER', 'score': 0.9994564, 'word': 'Julie Jacob', 'start': 5, 'end': 16}\n",
      "{'entity_group': 'PER', 'score': 0.98797685, 'word': 'Na', 'start': 5, 'end': 7}\n",
      "{'entity_group': 'PER', 'score': 0.94521886, 'word': '##l Paul', 'start': 9, 'end': 15}\n",
      "{'entity_group': 'PER', 'score': 0.8243458, 'word': 'Yegorov', 'start': 9, 'end': 16}\n",
      "{'entity_group': 'ORG', 'score': 0.7328082, 'word': 'Megan Rhodes Global', 'start': 0, 'end': 19}\n",
      "{'entity_group': 'PER', 'score': 0.78153634, 'word': 'Joseph Bocanegra', 'start': 5, 'end': 21}\n",
      "{'entity_group': 'PER', 'score': 0.99852186, 'word': 'C', 'start': 11, 'end': 12}\n",
      "{'entity_group': 'PER', 'score': 0.98733276, 'word': '##risto', 'start': 12, 'end': 17}\n",
      "{'entity_group': 'PER', 'score': 0.8120905, 'word': '##pher Miller', 'start': 17, 'end': 28}\n",
      "{'entity_group': 'ORG', 'score': 0.9973834, 'word': 'StubHub', 'start': 0, 'end': 7}\n",
      "{'entity_group': 'ORG', 'score': 0.97284144, 'word': 'StubHub', 'start': 0, 'end': 7}\n",
      "{'entity_group': 'ORG', 'score': 0.9960375, 'word': 'Blackstone', 'start': 4, 'end': 14}\n",
      "{'entity_group': 'ORG', 'score': 0.9973834, 'word': 'StubHub', 'start': 0, 'end': 7}\n",
      "{'entity_group': 'ORG', 'score': 0.9677215, 'word': 'StubHub', 'start': 0, 'end': 7}\n",
      "{'entity_group': 'PER', 'score': 0.86882246, 'word': 'Vanti', 'start': 4, 'end': 9}\n",
      "{'entity_group': 'LOC', 'score': 0.8842937, 'word': 'London', 'start': 4, 'end': 10}\n",
      "{'entity_group': 'ORG', 'score': 0.65514183, 'word': 'ES', 'start': 11, 'end': 13}\n",
      "{'entity_group': 'LOC', 'score': 0.98780954, 'word': 'London', 'start': 7, 'end': 13}\n",
      "{'entity_group': 'ORG', 'score': 0.40368274, 'word': 'GB', 'start': 14, 'end': 16}\n",
      "{'entity_group': 'PER', 'score': 0.99973464, 'word': 'Dan Much', 'start': 8, 'end': 16}\n",
      "{'entity_group': 'ORG', 'score': 0.49214205, 'word': 'Empleos', 'start': 9, 'end': 16}\n",
      "{'entity_group': 'ORG', 'score': 0.49214205, 'word': 'Empleos', 'start': 9, 'end': 16}\n",
      "{'entity_group': 'ORG', 'score': 0.49214205, 'word': 'Empleos', 'start': 9, 'end': 16}\n",
      "{'entity_group': 'ORG', 'score': 0.84728456, 'word': 'Empleos', 'start': 12, 'end': 19}\n",
      "{'entity_group': 'PER', 'score': 0.7191235, 'word': 'T', 'start': 0, 'end': 1}\n",
      "{'entity_group': 'PER', 'score': 0.7920987, 'word': 'Empleos', 'start': 10, 'end': 17}\n",
      "{'entity_group': 'ORG', 'score': 0.7994993, 'word': 'Prof', 'start': 0, 'end': 4}\n",
      "{'entity_group': 'ORG', 'score': 0.7855056, 'word': '##or Empleos de', 'start': 6, 'end': 19}\n",
      "{'entity_group': 'ORG', 'score': 0.7231126, 'word': 'Empleos de', 'start': 7, 'end': 17}\n",
      "{'entity_group': 'PER', 'score': 0.99700886, 'word': 'A', 'start': 0, 'end': 1}\n",
      "{'entity_group': 'PER', 'score': 0.7645851, 'word': '##bo', 'start': 1, 'end': 3}\n",
      "{'entity_group': 'PER', 'score': 0.64293444, 'word': '##gado Empleos', 'start': 3, 'end': 15}\n",
      "Name: C ##risto, Position: Chief Business Officer, Count: 2\n",
      "Name: Art Yegorov, Position: Chief Technology Officer, Count: 1\n",
      "Name: Na ##ku ##l Paul, Position: Vice President, Count: 1\n",
      "Name: Julie Jacob, Position: Director, Count: 1\n",
      "Name: Na ##l Paul, Position: Vice President, Count: 1\n",
      "Name: Dan Much, Position: CEO, Count: 1\n",
      "Name: A, Position: Director, Count: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "\n",
    "# Initialize BERT NER pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "def extract_management_info(text, nlp):\n",
    "    # Define common position titles\n",
    "    position_titles = [\n",
    "        \"CEO\", \"Chief Executive Officer\", \n",
    "        \"CFO\", \"Chief Financial Officer\", \n",
    "        \"COO\", \"Chief Operating Officer\", \n",
    "        \"CTO\", \"Chief Technology Officer\", \n",
    "        \"CMO\", \"Chief Marketing Officer\", \n",
    "        \"CBO\", \"Chief Business Officer\", \n",
    "        \"Director\", \"Vice President\", \"Board Member\",\n",
    "        \"VP\", \"President\", \"Chairman\", \"Founder\", \n",
    "        \"Owner\", \"Partner\", \"Head\", \"Independent Director\"\n",
    "    ]\n",
    "    \n",
    "    # Create a regex pattern to find names and positions\n",
    "    name_pattern = r'([A-Z][a-z]+(?: [A-Z][a-z]*){0,2})'\n",
    "    position_pattern = r'\\b(' + '|'.join(position_titles) + r')\\b'\n",
    "    combined_pattern = re.compile(rf'{name_pattern}\\s*,?\\s*{position_pattern}|{position_pattern}\\s*,?\\s*{name_pattern}', re.IGNORECASE)\n",
    "    \n",
    "    # Find all matches in the text\n",
    "    matches = combined_pattern.findall(text)\n",
    "    \n",
    "    # Extract names and positions\n",
    "    management_info = []\n",
    "    for match in matches:\n",
    "        filtered_match = [m for m in match if m]\n",
    "        if len(filtered_match) == 2:\n",
    "            name, position = (filtered_match[0].strip(), filtered_match[1].strip())\n",
    "            # Validate the name using BERT NER\n",
    "            ner_results = nlp(name)\n",
    "            full_name = []\n",
    "            for item in ner_results:\n",
    "                #print(item.keys())\n",
    "                print(item)\n",
    "                if item['entity_group'] == 'PER' and item['score'] >= 0.90:# and '#' not in item['word']:\n",
    "                    full_name.append(item['word'])\n",
    "            if full_name:\n",
    "                management_info.append((' '.join(full_name), position))\n",
    "    return management_info\n",
    "\n",
    "def clean_string(input_string):\n",
    "    # Use regex to replace non-alphanumeric characters with an empty string\n",
    "    cleaned_string = re.sub(r'[^a-zA-Z0-9\\s]', '', input_string)\n",
    "    return cleaned_string\n",
    "\n",
    "def find_full_word(text, substring):\n",
    "    # Find the first occurrence of the case-sensitive substring in the text using regex\n",
    "    pattern = r'\\b\\w*' + re.escape(substring) + r'\\w*\\b'\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        # Return the full word containing the substring\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "text = \"This is an example sentence. Let's find the Substring in this text.\"\n",
    "substring = \"Sub\"\n",
    "result = find_full_word(text, substring)\n",
    "print(result)  # Output: Substring\n",
    "\n",
    "name_position_pairs = []\n",
    "for key in search_results:\n",
    "    text = clean_string(key)\n",
    "    #print(text)\n",
    "    management_info = extract_management_info(text, nlp)\n",
    "    #print(management_info)\n",
    "    name_position_pairs.extend(management_info)\n",
    "#print(name_position_pairs)\n",
    "# Count occurrences of each name-position pair\n",
    "pair_counter = Counter(name_position_pairs)\n",
    "\n",
    "# Find the most common pairs\n",
    "most_common_pairs = pair_counter.most_common()\n",
    "\n",
    "# print the most common name-position pairs\n",
    "for pair, count in most_common_pairs:\n",
    "    print(f\"Name: {pair[0]}, Position: {pair[1]}, Count: {count}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
